{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e00038",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "41762264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import os\n",
    "import requests\n",
    "import fitz\n",
    "import json\n",
    "import torch\n",
    "import joblib\n",
    "import gzip\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from sqlalchemy.engine import URL\n",
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlalchemy import Integer, String, Float, Boolean, create_engine, select\n",
    "from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, Session\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "from pymilvus import MilvusClient\n",
    "from pymilvus import FieldSchema, DataType, CollectionSchema\n",
    "\n",
    "from google import genai\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bcad3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable, n):\n",
    "        \"batched('ABCDEFG', 3) -> ABC DEF G\"\n",
    "        if n < 1:\n",
    "            raise ValueError('n must be at least one')\n",
    "        it = iter(iterable)\n",
    "        while batch := tuple(islice(it, n)):\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0e3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
    "META_CSV_GZ = ROOT / \"images\" / \"metadata\" / \"images.csv.gz\"\n",
    "IMAGES_ROOT = ROOT / \"images\" / \"small\"\n",
    "\n",
    "PG_HOST = os.environ.get(\"PG_HOST\", \"localhost\")\n",
    "PG_PORT = int(os.environ.get(\"PG_PORT\", \"5432\"))\n",
    "PG_DB = os.environ.get(\"PG_DB\", \"similarity_search_service_db\")\n",
    "PG_USER = os.environ.get(\"PG_USER\", \"postgres\")\n",
    "PG_PASS = os.environ.get(\"PG_PASS\", \"password\")\n",
    "\n",
    "MIN_SIZE = int(os.environ.get(\"ABO_MIN_SIZE\", \"1000\"))\n",
    "MAX_IMAGES = int(os.environ.get(\"MAX_IMAGES\", \"500\"))\n",
    "BATCH_SIZE = int(os.environ.get(\"BATCH_SIZE\", str(joblib.cpu_count(only_physical_cores=True) or 4)))\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608d3e4",
   "metadata": {},
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "882ab44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images with >= 1px.\n"
     ]
    }
   ],
   "source": [
    "def extract_image_paths_csv(meta_csv_gz: Path, images_root: Path, min_size: int) -> list[Path]:\n",
    "    rows = []\n",
    "    with gzip.open(meta_csv_gz, \"rt\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                h = int(row[\"height\"])\n",
    "                w = int(row[\"width\"])\n",
    "            except (ValueError, KeyError):\n",
    "                continue\n",
    "            \n",
    "            if h >= min_size and w >= min_size:\n",
    "                p = images_root / row[\"path\"]\n",
    "                if p.exists():\n",
    "                    rows.append(p)\n",
    "    return rows\n",
    "\n",
    "image_paths = extract_image_paths_csv(META_CSV_GZ, IMAGES_ROOT, MIN_SIZE)\n",
    "print(f\"Found {len(image_paths)} images with >= {MIN_SIZE}px.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4cd670",
   "metadata": {},
   "source": [
    "### Database setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74d62ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_url = URL.create(\n",
    "    drivername=\"postgresql+psycopg\",\n",
    "    username=PG_USER,\n",
    "    password=PG_PASS,\n",
    "    host=PG_HOST,\n",
    "    port=PG_PORT,\n",
    "    database=PG_DB,\n",
    ")\n",
    "engine = sqlalchemy.create_engine(pg_url, echo=False, pool_pre_ping=True)\n",
    "\n",
    "class Base(DeclarativeBase):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bf47861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img(Base):\n",
    "    __tablename__ = \"images\"\n",
    "    __table_args__ = {'extend_existing': True}\n",
    "    \n",
    "    VECTOR_LENGTH: int = 512\n",
    "    \n",
    "    id: Mapped[int] = mapped_column(primary_key=True)\n",
    "    image_path: Mapped[str] = mapped_column(sqlalchemy.Text, nullable=False, unique=True)\n",
    "    embedding: Mapped[list[float]] = mapped_column(Vector(dim=VECTOR_LENGTH), nullable=False)\n",
    "    \n",
    "# Create table\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b4762",
   "metadata": {},
   "source": [
    "### Image vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0d872c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"clip-ViT-B-32\", device=DEVICE)\n",
    "\n",
    "\n",
    "def insert_images(engine, images):\n",
    "    with Session(engine) as session:\n",
    "        session.bulk_save_objects(images, return_defaults=False)\n",
    "        session.commit()\n",
    "\n",
    "def vectorize_images(engine, model, image_paths):\n",
    "    image_paths_to_process = image_paths[:MAX_IMAGES]\n",
    "    with tqdm(total=len(image_paths_to_process)) as pbar:\n",
    "        for images_paths_batch in  batched(image_paths_to_process, BATCH_SIZE):\n",
    "            paths_batch = list(images_paths_batch)\n",
    "            images = [Image.open(path) for path in images_paths_batch]\n",
    "            # calculate embeddings\n",
    "            emb = model.encode(images, batch_size=len(images), convert_to_numpy=True, normalize_embeddings=True) \n",
    "            # create Img instances for all images in batch\n",
    "            objs = [Img(image_path=str(p), embedding=emb[i].tolist()) for i, p in enumerate(paths_batch)]\n",
    "            # insert all batch images\n",
    "            insert_images(engine, objs)\n",
    "            # update pbar\n",
    "            pbar.update(len(objs))\n",
    "\n",
    "vectorize_images(engine, model, image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a0ba6d",
   "metadata": {},
   "source": [
    "### Search and results display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "27d8b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageSearch:\n",
    "    def __init__(self, engine, model):\n",
    "        self.engine = engine\n",
    "        self.model = model\n",
    "        \n",
    "    def __call__(self, image_description: str, k: int):\n",
    "        found_images = self.find_similar_images(image_description, k)\n",
    "        self.display_images(found_images)\n",
    "        return found_images\n",
    "\n",
    "    def find_similar_images(self, image_description: str, k: int):\n",
    "        image_embedding = self.model.encode([image_description], convert_to_numpy=True, normalize_embeddings=True)[0]        \n",
    "        # remember about session and commit\n",
    "        with Session(self.engine) as session:\n",
    "\n",
    "            query = (\n",
    "                    select(Img)\n",
    "                    .order_by(Img.embedding.cosine_distance(image_embedding))\n",
    "                    .limit(k)\n",
    "            )\n",
    "        \n",
    "        result = session.execute(query).scalars().all()\n",
    "        return result\n",
    "    \n",
    "    def display_images(self, images):\n",
    "        fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "        \n",
    "        for i, img_path in enumerate(images):\n",
    "            img = Image.open(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis(\"off\")\n",
    "            axes[i].set_title(f\"Image {i+1}\")\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4775255c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of columns must be a positive integer, not 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m search = ImageSearch(engine, model)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m res = \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpencil\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mImageSearch.__call__\u001b[39m\u001b[34m(self, image_description, k)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_description: \u001b[38;5;28mstr\u001b[39m, k: \u001b[38;5;28mint\u001b[39m):\n\u001b[32m      7\u001b[39m     found_images = \u001b[38;5;28mself\u001b[39m.find_similar_images(image_description, k)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisplay_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfound_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m found_images\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mImageSearch.display_images\u001b[39m\u001b[34m(self, images)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdisplay_images\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     fig, axes = \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, img_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n\u001b[32m     29\u001b[39m         img = Image.open(img_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lchec\\Desktop\\MLOps4\\.venv\\Lib\\site-packages\\matplotlib\\pyplot.py:1777\u001b[39m, in \u001b[36msubplots\u001b[39m\u001b[34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[39m\n\u001b[32m   1632\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1633\u001b[39m \u001b[33;03mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[32m   1634\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m fig = figure(**fig_kw)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m axs = \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharex\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharey\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m                   \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m=\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lchec\\Desktop\\MLOps4\\.venv\\Lib\\site-packages\\matplotlib\\figure.py:918\u001b[39m, in \u001b[36mFigureBase.subplots\u001b[39m\u001b[34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[39m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mwidth_ratios\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must not be defined both as \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    915\u001b[39m                          \u001b[33m\"\u001b[39m\u001b[33mparameter and as key in \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgridspec_kw\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    916\u001b[39m     gridspec_kw[\u001b[33m'\u001b[39m\u001b[33mwidth_ratios\u001b[39m\u001b[33m'\u001b[39m] = width_ratios\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m gs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_gridspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m axs = gs.subplots(sharex=sharex, sharey=sharey, squeeze=squeeze,\n\u001b[32m    920\u001b[39m                   subplot_kw=subplot_kw)\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m axs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lchec\\Desktop\\MLOps4\\.venv\\Lib\\site-packages\\matplotlib\\figure.py:1600\u001b[39m, in \u001b[36mFigureBase.add_gridspec\u001b[39m\u001b[34m(self, nrows, ncols, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[33;03mLow-level API for creating a `.GridSpec` that has this figure as a parent.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1596\u001b[39m \n\u001b[32m   1597\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1599\u001b[39m _ = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# pop in case user has added this...\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1600\u001b[39m gs = \u001b[43mGridSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1601\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m gs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lchec\\Desktop\\MLOps4\\.venv\\Lib\\site-packages\\matplotlib\\gridspec.py:363\u001b[39m, in \u001b[36mGridSpec.__init__\u001b[39m\u001b[34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28mself\u001b[39m.hspace = hspace\n\u001b[32m    361\u001b[39m \u001b[38;5;28mself\u001b[39m.figure = figure\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lchec\\Desktop\\MLOps4\\.venv\\Lib\\site-packages\\matplotlib\\gridspec.py:51\u001b[39m, in \u001b[36mGridSpecBase.__init__\u001b[39m\u001b[34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     49\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of rows must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnrows\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ncols, Integral) \u001b[38;5;129;01mor\u001b[39;00m ncols <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     52\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of columns must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mncols\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._nrows, \u001b[38;5;28mself\u001b[39m._ncols = nrows, ncols\n\u001b[32m     54\u001b[39m \u001b[38;5;28mself\u001b[39m.set_height_ratios(height_ratios)\n",
      "\u001b[31mValueError\u001b[39m: Number of columns must be a positive integer, not 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search = ImageSearch(engine, model)\n",
    "res = search(\"pencil\", k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
