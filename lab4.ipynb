{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a483b3",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43927573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import os\n",
    "import requests\n",
    "import fitz\n",
    "import json\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from sqlalchemy.engine import URL\n",
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlalchemy import Integer, String, Float, Boolean, create_engine, select\n",
    "from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, Session\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from pymilvus import MilvusClient\n",
    "from pymilvus import FieldSchema, DataType, CollectionSchema\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from typing import List, Optional\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3882c015",
   "metadata": {},
   "source": [
    "### SQLacademy setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e33da954",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = URL.create(\n",
    "    drivername=\"postgresql+psycopg\",\n",
    "    username=\"postgres\",\n",
    "    password=\"password\",\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    database=\"similarity_search_service_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "663cc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base class for the table definition\n",
    "class Base(DeclarativeBase):\n",
    "    __abstract__ = True\n",
    "\n",
    "\n",
    "# Create the table definition\n",
    "class Images(Base):\n",
    "    __tablename__ = \"images\"\n",
    "    VECTOR_LENGTH = 512\n",
    "    \n",
    "    # primary key\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    # image path - we will use it to store the path to the image file, after similarity search we can use it to retrieve the image and display it\n",
    "    image_path: Mapped[str] = mapped_column(String(256))\n",
    "    # image embedding - we will store the image embedding in this column, the image embedding is a list of 512 floats this is the output of the sentence transformer model\n",
    "    image_embedding: Mapped[List[float]] = mapped_column(Vector(VECTOR_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75016c85",
   "metadata": {},
   "source": [
    "### create engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27e30d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(db_url)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638fa15",
   "metadata": {},
   "source": [
    "### SQLAlchemy queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0e19080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_0.jpg',\n",
       " 'image_40.jpg',\n",
       " 'image_98.jpg',\n",
       " 'image_90.jpg',\n",
       " 'image_61.jpg',\n",
       " 'image_3.jpg',\n",
       " 'image_9.jpg',\n",
       " 'image_66.jpg',\n",
       " 'image_96.jpg',\n",
       " 'image_8.jpg']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reusable function to insert data into the table\n",
    "def insert_image(engine: sqlalchemy.Engine, image_path: str, image_embedding: list[float]):\n",
    "    with Session(engine) as session:\n",
    "        # create the image object\n",
    "        image = Images(\n",
    "            image_path=image_path,\n",
    "            image_embedding=image_embedding\n",
    "        )\n",
    "        # add the image object to the session\n",
    "        session.add(image)\n",
    "        # commit the transaction\n",
    "        session.commit()\n",
    "\n",
    "# insert some data into the table\n",
    "N = 100\n",
    "for i in range(N):\n",
    "    image_path = f\"image_{i}.jpg\"\n",
    "    image_embedding = np.random.rand(512).tolist()\n",
    "    insert_image(engine, image_path, image_embedding)\n",
    "\n",
    "# select first image from the table\n",
    "with Session(engine) as session:\n",
    "    image = session.query(Images).first()\n",
    "\n",
    "\n",
    "# calculate the cosine similarity between the first image and the K rest of the images, order the images by the similarity score\n",
    "def find_k_images(engine, k: int, orginal_image: Images):\n",
    "    with Session(engine) as session:\n",
    "        result = session.execute(\n",
    "            select(Images)\n",
    "            .order_by(Images.image_embedding.cosine_distance(orginal_image.image_embedding))\n",
    "            .limit(k), \n",
    "            execution_options={\"prebuffer_rows\": True}\n",
    "        )\n",
    "        return list(result.scalars().all())\n",
    "\n",
    "# find the 10 most similar images to the first image\n",
    "\n",
    "top10 = find_k_images(engine, 10, image) \n",
    "[img.image_path for img in top10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69168fbe",
   "metadata": {},
   "source": [
    "### filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ef2e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_images_with_similarity_score_greater_than(engine, similarity_score: float, orginal_image: Images):\n",
    "    with Session(engine) as session:\n",
    "        result = session.execute(\n",
    "            select(Image)\n",
    "            .filter(Image.image_embedding.cosine_similarity(orginal_image.image_embedding) > similarity_score), \n",
    "            execution_options={\"prebuffer_rows\": True}\n",
    "        )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a08d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc10e09adef4833a3f9bcc141070721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lchec\\Desktop\\MLOps4\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lchec\\.cache\\huggingface\\hub\\datasets--FronkonGames--steam-games-dataset. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afea4bbf2af647b88cf40977f851c4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-e2ed184370a06932.parquet:   0%|          | 0.00/123M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bb02cb091b4efeb3bf7b6de7d8ed15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/83560 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AppID': Value('int64'), 'Name': Value('string'), 'Release date': Value('string'), 'Estimated owners': Value('string'), 'Peak CCU': Value('int64'), 'Required age': Value('int64'), 'Price': Value('float64'), 'DLC count': Value('int64'), 'About the game': Value('string'), 'Supported languages': Value('string'), 'Full audio languages': Value('string'), 'Reviews': Value('string'), 'Header image': Value('string'), 'Website': Value('string'), 'Support url': Value('string'), 'Support email': Value('string'), 'Windows': Value('bool'), 'Mac': Value('bool'), 'Linux': Value('bool'), 'Metacritic score': Value('int64'), 'Metacritic url': Value('string'), 'User score': Value('int64'), 'Positive': Value('int64'), 'Negative': Value('int64'), 'Score rank': Value('float64'), 'Achievements': Value('int64'), 'Recommendations': Value('int64'), 'Notes': Value('string'), 'Average playtime forever': Value('int64'), 'Average playtime two weeks': Value('int64'), 'Median playtime forever': Value('int64'), 'Median playtime two weeks': Value('int64'), 'Developers': Value('string'), 'Publishers': Value('string'), 'Categories': Value('string'), 'Genres': Value('string'), 'Tags': Value('string'), 'Screenshots': Value('string'), 'Movies': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"FronkonGames/steam-games-dataset\")\n",
    "\n",
    "# get columns names and types\n",
    "columns = dataset[\"train\"].features\n",
    "print(columns)\n",
    "\n",
    "columns_to_keep = [\"Name\", \"Windows\", \"Linux\", \"Mac\", \"About the game\", \"Supported languages\", \"Price\"]\n",
    "\n",
    "N = 40000\n",
    "dataset = dataset[\"train\"].select_columns(columns_to_keep).select(range(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c30433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Games(Base):\n",
    "    __tablename__ = \"games\"\n",
    "    __table_args__ = {'extend_existing': True}\n",
    "    \n",
    "    # the vector size produced by the model taken from documentation https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2\n",
    "    VECTOR_LENGTH = 512\n",
    "        \n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    name: Mapped[str] = mapped_column(String(256))\n",
    "    description: Mapped[str] = mapped_column(String(4096))\n",
    "    windows: Mapped[bool] = mapped_column(Boolean)\n",
    "    linux: Mapped[bool] = mapped_column(Boolean)\n",
    "    mac: Mapped[bool] = mapped_column(Boolean)\n",
    "    price: Mapped[float] = mapped_column(Float)\n",
    "    game_description_embedding: Mapped[List[float]] = mapped_column(Vector(VECTOR_LENGTH))\n",
    "\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f84573ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca6906b67814a0aa36d24eefcf914da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lchec\\Desktop\\MLOps4\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lchec\\.cache\\huggingface\\hub\\models--sentence-transformers--distiluse-base-multilingual-cased-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2dd84e99a541ab98b786e959bc07c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd7d1ea69144c1ca993d9c653dd6613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb040929f12c4c7da1a74e87ec355e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f3fa5e925a4cc1892520c85bd4cb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7315e9b1ba4c43a4878731d3d9a3ccc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb92125011d04b4a97e6e5382fb2fc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f441ca9c9b481aaa9425b28f48c6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb253a7c168c4210a81a6b6c9923aad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b402de3927534d808c1724630a183559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd999aaa9ed54752b4a51c7c3353a076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493b8bb868484fd0bdbae7825328c5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d10631dde14119bf1670edc4d6ccf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"distiluse-base-multilingual-cased-v2\"\n",
    "model = SentenceTransformer(checkpoint)\n",
    "\n",
    "\n",
    "def generate_embeddings(text: str) -> list[float]:\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5eec8",
   "metadata": {},
   "source": [
    "### insert data into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0bb4d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [47:08<00:00, 14.14it/s] \n"
     ]
    }
   ],
   "source": [
    "def insert_games(engine, dataset):\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "        for i, game in enumerate(dataset):\n",
    "            game_description = game[\"About the game\"] or \"\"\n",
    "            game_embedding = generate_embeddings(game_description)\n",
    "            name, windows, linux, mac, price = game[\"Name\"], game[\"Windows\"], game[\"Linux\"], game[\"Mac\"], game[\"Price\"]\n",
    "            if name and windows and linux and mac and price and game_description:\n",
    "                game = Games(\n",
    "                    name=game[\"Name\"], \n",
    "                    description=game_description[0:4096],\n",
    "                    windows=game[\"Windows\"], \n",
    "                    linux=game[\"Linux\"], \n",
    "                    mac=game[\"Mac\"], \n",
    "                    price=game[\"Price\"], \n",
    "                    game_description_embedding=game_embedding\n",
    "                )\n",
    "                with Session(engine) as session:\n",
    "                    session.add(game)\n",
    "                    session.commit()\n",
    "            pbar.update(1)\n",
    "            \n",
    "insert_games(engine, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "211c3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_game(\n",
    "    engine: sqlalchemy.Engine, \n",
    "    game_description: str, \n",
    "    windows: Optional[bool] = None, \n",
    "    linux: Optional[bool] = None,\n",
    "    mac: Optional[bool] = None,\n",
    "    price: Optional[int] = None\n",
    "):\n",
    "    with Session(engine) as session:\n",
    "        game_embedding = generate_embeddings(game_description)\n",
    "    \n",
    "        query = (\n",
    "            select(Games)\n",
    "            .order_by(Games.game_description_embedding.cosine_distance(game_embedding))\n",
    "        )\n",
    "        \n",
    "        if price:\n",
    "            query = query.filter(Games.price <= price)\n",
    "        if windows:\n",
    "            query = query.filter(Games.windows == True)\n",
    "        if linux:\n",
    "            query = query.filter(Games.linux == True)\n",
    "        if mac:\n",
    "            query = query.filter(Games.mac == True)\n",
    "        \n",
    "        result = session.execute(query, execution_options={\"prebuffer_rows\": True})\n",
    "        game = result.scalars().first()\n",
    "        \n",
    "        return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e116f062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: Ultimate Spider Hero\n",
      "Description: Ultimate Spider Hero game was designed for real heroes! Your mission is to help poor residents of the Metropolis and to save them from the terrible monsters. Move forward to fight your enemies and try not to fall! Features: Simple and addictive gameplay Nice graphics Awesome Ultimate Spider Hero Countless Steam achievements for you to collect! Compatibility with multiple major platforms (Windows, Mac, Linux, SteamOS) Make your way through the endless labyrinths of long, confusing city streets together with your favorite hero from countless movies and cartoons! Although this may look simple enough, things are not as easy as they seem. You will have to learn how to cling into houses properly using your web, otherwise you will fall to your demise. If you manage to do so - you will become a real superhero, armed with elusiveness, agility and speed and the ability to tirelessly swing across the rooftops and between the huge skyscrapers this urban landscape has to offer in this thrilling game of a super spider. It's fun, the visuals are magnificent and the controls are simple!\n",
      "Game: 3D PUZZLE - Modern House\n",
      "Description: Collect a 3D puzzle, transferring things to the right places to create a beautiful house. You need to go to the item, take it by pressing the left mouse button and take the item to the desired location marked in green. If you brought the correct item, it will snap into place and you will receive leaderboard points and achievements for this. Collect as much substance as possible as quickly as possible to get more points for the leaderboard. If you brought the wrong item, you can throw it away, it will return to the starting location so that you can pick it up again.\n"
     ]
    }
   ],
   "source": [
    "game = find_game(engine, \"This is a game about a hero who saves the world\", price=10)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")\n",
    "\n",
    "game = find_game(engine, game_description=\"Home decorating\", price=20)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef744f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: 3D PUZZLE - Old House\n",
      "Description: Collect a 3D puzzle, transferring things to the right places to create a beautiful house. You need to go to the item, take it by pressing the left mouse button and take the item to the desired location marked in green. If you brought the correct item, it will snap into place and you will receive leaderboard points and achievements for this. Collect as much substance as possible as quickly as possible to get more points for the leaderboard. If you brought the wrong item, you can throw it away, it will return to the starting location so that you can pick it up again.\n"
     ]
    }
   ],
   "source": [
    "game = find_game(engine, game_description=\"Home decorating\", mac=True, price=5)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a428332e",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation (RAG) service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d165792",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"localhost\"\n",
    "port = \"19530\"\n",
    "\n",
    "milvus_client = MilvusClient(\n",
    "    host=host,\n",
    "    port=port\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2f1eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_LENGTH = 768  # check the dimensionality for Silver Retriever Base (v1.1) model\n",
    "\n",
    "id_field = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, description=\"Primary id\")\n",
    "text = FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=4096, description=\"Page text\")\n",
    "embedding_text = FieldSchema(\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=VECTOR_LENGTH, description=\"Embedded text\")\n",
    "\n",
    "fields = [id_field, text, embedding_text]\n",
    "\n",
    "schema = CollectionSchema(fields=fields, auto_id=True, enable_dynamic_field=True, description=\"RAG Texts collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75cbe4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rag_texts_and_embeddings']\n",
      "{'collection_name': 'rag_texts_and_embeddings', 'auto_id': True, 'num_shards': 1, 'description': 'RAG Texts collection', 'fields': [{'field_id': 100, 'name': 'id', 'description': 'Primary id', 'type': <DataType.INT64: 5>, 'params': {}, 'auto_id': True, 'is_primary': True}, {'field_id': 101, 'name': 'text', 'description': 'Page text', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 4096}}, {'field_id': 102, 'name': 'embedding', 'description': 'Embedded text', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}], 'functions': [], 'aliases': [], 'collection_id': 462109652559856479, 'consistency_level': 2, 'properties': {}, 'num_partitions': 1, 'enable_dynamic_field': True, 'created_timestamp': 462109697342177286}\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME = \"rag_texts_and_embeddings\"\n",
    "\n",
    "milvus_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "index_params = milvus_client.prepare_index_params()\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"embedding\", \n",
    "    index_type=\"HNSW\",\n",
    "    metric_type=\"L2\",\n",
    "    params={\"M\": 4, \"efConstruction\": 64}  # lower values for speed\n",
    ") \n",
    "\n",
    "milvus_client.create_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    index_params=index_params\n",
    ")\n",
    "\n",
    "# checkout our collection\n",
    "print(milvus_client.list_collections())\n",
    "\n",
    "# describe our collection\n",
    "print(milvus_client.describe_collection(COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56674531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data source and destination\n",
    "## the document origin destination from which document will be downloaded \n",
    "pdf_url = \"https://www.iab.org.pl/wp-content/uploads/2024/04/Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the document\n",
    "file_name = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the processed document \n",
    "file_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.json\"\n",
    "\n",
    "## local destination of the embedded pages of the document\n",
    "embeddings_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska-Embeddings.json\"\n",
    "\n",
    "## local destination of all above local required files\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "235bd76b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data\\\\Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(data_dir, embeddings_json), \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     36\u001b[39m         json.dump(out, f, indent=\u001b[32m2\u001b[39m, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mdownload_pdf_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m extract_pdf_text(file_name, file_json)\n\u001b[32m     41\u001b[39m device = \u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mdownload_pdf_data\u001b[39m\u001b[34m(pdf_url, file_name)\u001b[39m\n\u001b[32m      7\u001b[39m r = requests.get(pdf_url, stream=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m r.raise_for_status()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m r.iter_content(\u001b[32m1024\u001b[39m):\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m block:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lchec\\Desktop\\MLOps4\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data\\\\Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf'"
     ]
    }
   ],
   "source": [
    "def download_pdf_data(pdf_url: str, file_name: str) -> None:\n",
    "    dest = os.path.join(data_dir, file_name)\n",
    "\n",
    "    if os.path.exists(dest):\n",
    "        return\n",
    "\n",
    "    r = requests.get(pdf_url, stream=True)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    with open(dest, 'wb') as f:\n",
    "        for block in r.iter_content(1024):\n",
    "            if block:\n",
    "                f.write(block)\n",
    "\n",
    "def extract_pdf_text(file_name, file_json):\n",
    "    document = fitz.open(os.path.join(data_dir, file_name))\n",
    "    pages = []\n",
    "\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        page_text = page.get_text()\n",
    "        pages.append({'page_num': page_num, 'text': page_text})\n",
    "\n",
    "    with open(os.path.join(data_dir, file_json), 'w', encoding='utf-8') as f:\n",
    "        json.dump(pages, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def generate_embeddings(file_json, embeddings_json, model):\n",
    "    with open(os.path.join(data_dir, file_json), 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    pages = [p['text'] for p in data]\n",
    "    embeddings = model.encode(pages)\n",
    "    out = [{'page_num': i, 'embedding': embeddings[i].tolist()} for i in range(len(embeddings))]\n",
    "\n",
    "    with open(os.path.join(data_dir, embeddings_json), 'w', encoding='utf-8') as f:\n",
    "        json.dump(out, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "download_pdf_data(pdf_url, file_name)\n",
    "extract_pdf_text(file_name, file_json)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "retriever_model = SentenceTransformer('ipipan/silver-retriever-base-v1.1', device=device)\n",
    "generate_embeddings(file_json, embeddings_json, retriever_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
